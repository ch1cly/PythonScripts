{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gym import Env\n",
    "from gym.spaces import Box, Discrete\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from time import sleep, time"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "n4mt8v_NGVEw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668110769966,
     "user_tz": -180,
     "elapsed": 403,
     "user": {
      "displayName": "Тимур Бикбулатов",
      "userId": "18059606190986610747"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "class Point2():\n",
    "    def __init__(self,x=0,y=0):\n",
    "        self._info = np.array([x,y],ndmin=1)\n",
    "\n",
    "    @property\n",
    "    def x(self):\n",
    "        return self._info[0]\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._info[1]\n",
    "\n",
    "    @x.setter\n",
    "    def x(self, a):\n",
    "        self._info[0] = a\n",
    "\n",
    "    @y.setter\n",
    "    def y(self, a):\n",
    "        self._info[1] = a\n",
    "\n",
    "    def __add__(self, o):\n",
    "        return Point2(self._info[0] + o._info[0], self._info[1] + o._info[1])\n",
    "\n",
    "    def __sub__(self, o):\n",
    "        return Point2(self._info[0] - o._info[0], self._info[1] - o._info[1])\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if np.all(np.equal(self._info,other._info)):\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "zCdy-TAwGVEx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668110771097,
     "user_tz": -180,
     "elapsed": 3,
     "user": {
      "displayName": "Тимур Бикбулатов",
      "userId": "18059606190986610747"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "class CustomEnv(Env):\n",
    "    def __init__(self, w):\n",
    "        self.WIDTH = w\n",
    "        self.action_space = Discrete(4)\n",
    "        self.observation_space = Discrete((self.WIDTH+2)**2)\n",
    "        self.player = Point2(0,0)\n",
    "        self.gift = Point2(0,0)\n",
    "        self.aim = Point2(0,-1)\n",
    "        self.holes = [Point2(0,0)]\n",
    "        self.endGame = False\n",
    "        '''\n",
    "        t.onkey(lambda: self.change(1, 0), 'Right')\n",
    "        t.onkey(lambda: self.change(-1, 0), 'Left')\n",
    "        t.onkey(lambda: self.change(0, 1), 'Up')\n",
    "        t.onkey(lambda: self.change(0, -1), 'Down')\n",
    "        '''\n",
    "\n",
    "    def inside(self):\n",
    "        return -1 < self.player .x < self.WIDTH and -1 < self.player.y < self.WIDTH\n",
    "\n",
    "    def change(self,action):\n",
    "        if action == 0:\n",
    "            self.aim.x = 0\n",
    "            self.aim.y = -1\n",
    "        elif action == 1:\n",
    "            self.aim.x = -1\n",
    "            self.aim.y = 0\n",
    "        elif action == 2:\n",
    "            self.aim.x = 0\n",
    "            self.aim.y = 1\n",
    "        elif action == 3:\n",
    "            self.aim.x = 1\n",
    "            self.aim.y = 0\n",
    "        else:\n",
    "            print('Error, no such key\\n')\n",
    "\n",
    "    def step(self, action):\n",
    "        self.change(action)\n",
    "        t = False\n",
    "        oldpos = self.player\n",
    "        self.player = self.player + self.aim\n",
    "\n",
    "        if not self.inside() or self.player in self.holes:\n",
    "            self.endGame = True\n",
    "            reward = -20\n",
    "            done = True\n",
    "            t = False\n",
    "        else:\n",
    "            done = False\n",
    "            if self.player == self.gift:\n",
    "                reward = 70\n",
    "                done = True\n",
    "                t = True\n",
    "            else:\n",
    "                prev = np.array([np.abs(oldpos.x-self.gift.x),np.abs(oldpos.y-self.gift.y)])\n",
    "                cur =  np.array([np.abs(self.player.x-self.gift.x),np.abs(self.player.y-self.gift.y)])\n",
    "\n",
    "                if prev[0] < cur[0] or prev[1] < cur[1]:\n",
    "                    reward = -2\n",
    "                else:\n",
    "                    reward = 0\n",
    "        # Setting the placeholder for info\n",
    "        info = {}\n",
    "        # Returning the step information\n",
    "        return self.playerPos(), reward, done,t , info\n",
    "\n",
    "    def render(self,episode,t):\n",
    "        clear_output(wait=True)\n",
    "        s = ''\n",
    "        for i in range(-1,self.WIDTH+1):\n",
    "            for j in range(-1,self.WIDTH+1):\n",
    "                if Point2(i,j) == self.player:\n",
    "                    s = s + '@'\n",
    "                elif Point2(i,j) in self.holes:\n",
    "                    s = s + '█'\n",
    "                elif Point2(i,j) == self.gift:\n",
    "                    s = s + 'X'\n",
    "                elif j == -1 or j == self.WIDTH:\n",
    "                    s = s + '‖'\n",
    "                elif i == -1 or i == self.WIDTH:\n",
    "                    s = s + '='\n",
    "                else:\n",
    "                    s = s + '·'\n",
    "            s = s + '\\n'\n",
    "        s = s + 'Episode:{} Win:{}'.format(episode,t)\n",
    "        print(s)\n",
    "\n",
    "    def playerPos(self):\n",
    "        return self.player.x*self.WIDTH + self.player.y\n",
    "\n",
    "    def rPoint(self):\n",
    "        x = random.randint(0,self.WIDTH-1)\n",
    "        y = random.randint(0,self.WIDTH-1)\n",
    "        return Point2(x, y)\n",
    "\n",
    "    def reset(self,seed=2,amountHoles=-1,playerSeed=False):\n",
    "        if amountHoles == -1:\n",
    "            amountHoles = self.WIDTH\n",
    "        random.seed(1)\n",
    "        self.gift = self.rPoint()\n",
    "        for i in range(amountHoles):\n",
    "            self.holes.append(self.rPoint())\n",
    "        self.aim = Point2(0, -1)\n",
    "        if playerSeed:\n",
    "          t = 1000 * time() # current time in milliseconds\n",
    "          random.seed(int(t) % 2**32)\n",
    "        self.player = self.rPoint()\n",
    "        while self.player in self.holes and self.player != self.gift:\n",
    "            self.player = self.rPoint()\n",
    "\n",
    "        self.endGame = False\n",
    "        return self.playerPos()\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "c-jfplGjGVEy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668110774816,
     "user_tz": -180,
     "elapsed": 4,
     "user": {
      "displayName": "Тимур Бикбулатов",
      "userId": "18059606190986610747"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space 144\n",
      "Action space 4\n"
     ]
    }
   ],
   "source": [
    "env = CustomEnv(10)\n",
    "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "# env.observation.n, env.action_space.n gives number of states and action in env loaded\n",
    "print(f'Observation space {env.observation_space.n}'.format(env.observation_space.n))\n",
    "print(f'Action space {env.action_space.n}'.format(env.action_space.n))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3SJsnfwGVEy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668110778844,
     "user_tz": -180,
     "elapsed": 580,
     "user": {
      "displayName": "Тимур Бикбулатов",
      "userId": "18059606190986610747"
     }
    },
    "outputId": "21223662-3582-4dd6-97fb-ebde40f0f5d5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "# 2. Parameters of Q-learning\n",
    "eta = .628\n",
    "gma = .9\n",
    "epis = 100\n",
    "rev_list = [] # rewards per episode calculate"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ocBYvP3vGVEz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668110783343,
     "user_tz": -180,
     "elapsed": 779,
     "user": {
      "displayName": "Тимур Бикбулатов",
      "userId": "18059606190986610747"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‖==========‖\n",
      "‖█·····@█··‖\n",
      "‖····█··█··‖\n",
      "‖·········X‖\n",
      "‖··········‖\n",
      "‖···█······‖\n",
      "‖··········‖\n",
      "‖···█·····█‖\n",
      "‖·······█··‖\n",
      "‖··········‖\n",
      "‖·█········‖\n",
      "‖==========‖\n",
      "Episode:99 Win:False\n",
      "Reward Sum on all episodes 26.68\n",
      "Final Values Q-Table\n",
      "[[  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.         -12.56         0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [-12.56         0.           0.           0.        ]\n",
      " [ -1.256      -12.56       -12.56        24.846192  ]\n",
      " [  0.         -12.56         0.           0.        ]\n",
      " [ -1.256        0.           0.           0.        ]\n",
      " [ -1.256       -1.256        0.           7.80656249]\n",
      " [ -1.256        0.         -12.56         0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [-12.56         0.           0.           0.        ]\n",
      " [  0.         -12.56       -12.56         0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.          -1.256        0.          38.8063442 ]\n",
      " [ -1.256       -1.256      -12.56        81.53657454]\n",
      " [-12.56         0.           0.88823041  -1.256     ]\n",
      " [ -1.256        0.          13.40348819  -1.256     ]\n",
      " [ -1.256       -1.256       27.73289855  -1.256     ]\n",
      " [ -1.256       -1.256       32.12219021  -1.256     ]\n",
      " [ -1.256      -12.56        38.02034265  -1.256     ]\n",
      " [ -1.256       -1.256       48.27816309  -1.256     ]\n",
      " [ -1.256       -1.256        0.          61.31730458]\n",
      " [ -1.256      -12.56        59.75655462  -1.256     ]\n",
      " [ -1.256       -1.256      103.79522149  -1.256     ]\n",
      " [  0.           0.           0.          37.5503442 ]\n",
      " [-12.56         0.           0.          -1.256     ]\n",
      " [ -1.256        0.           0.          -1.256     ]\n",
      " [ -1.256       21.93203304   0.          -1.256     ]\n",
      " [ -1.256        0.           0.         -12.56      ]\n",
      " [ -1.256        0.          18.22022286   0.        ]\n",
      " [ -1.256        0.          39.98022225  -1.256     ]\n",
      " [ -1.256        0.          74.73512762  -1.256     ]\n",
      " [ -1.256        0.          84.05459802  -1.256     ]\n",
      " [ -1.256       93.41395546   0.          -1.256     ]\n",
      " [ -1.256       90.72478512 -12.56        -1.256     ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [ -1.256        0.           0.          -1.256     ]\n",
      " [ -1.256       12.54780005 -12.56        -1.256     ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [ -1.256        0.           0.          -1.256     ]\n",
      " [ -1.256       37.41097587   0.          -1.256     ]\n",
      " [ -1.256       74.52016066   0.          -1.256     ]\n",
      " [ -1.256       69.68066007   0.          -1.256     ]\n",
      " [ -1.256       53.64670515   0.          -1.256     ]\n",
      " [-12.56         0.           0.          -1.256     ]\n",
      " [ -1.256        0.           0.          -1.256     ]\n",
      " [ -1.256        0.          11.4957635   -1.256     ]\n",
      " [ -1.256      -12.56        24.27492315 -12.56      ]\n",
      " [ -1.256        0.          32.58771213  -1.256     ]\n",
      " [ -1.256        0.          39.37131839  -1.256     ]\n",
      " [ -1.256        0.          50.08747349  -1.256     ]\n",
      " [ -1.256       62.96581105   0.          -1.256     ]\n",
      " [ -1.256       40.84541432   0.           0.        ]\n",
      " [  0.          29.71513129 -12.56       -12.56      ]\n",
      " [  4.23499221   0.           0.          -1.256     ]\n",
      " [ -1.256        0.           0.           0.        ]\n",
      " [ -1.256        2.02912738 -12.56        -1.256     ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [-12.56        11.62495805   0.          -1.256     ]\n",
      " [ -1.256       32.60295014   0.          -1.256     ]\n",
      " [ -1.256       31.42716235   0.           0.        ]\n",
      " [ -1.256        0.           0.         -12.56      ]\n",
      " [ -1.256       20.10614573 -12.56        -1.256     ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [-12.56         0.           0.          -1.256     ]\n",
      " [ -1.256        0.           0.          -1.256     ]\n",
      " [ -1.256        0.           0.          -1.256     ]\n",
      " [ -1.256        0.           0.          -1.256     ]\n",
      " [ -1.256        0.          13.28375859  -1.256     ]\n",
      " [ -1.256       24.91124965   0.          -1.256     ]\n",
      " [  0.          15.54210205   0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [-12.56         4.42196123  -0.97397073  -1.256     ]\n",
      " [ -1.8970423  -12.56       -12.56        -2.44753056]\n",
      " [-12.56         0.           0.           0.        ]\n",
      " [ -1.256        0.           0.         -12.56      ]\n",
      " [ -1.256        0.           0.          -1.256     ]\n",
      " [ -1.256        0.           0.          -1.256     ]\n",
      " [ -1.256        3.39694257   0.          -1.256     ]\n",
      " [ -1.256        0.           0.          -1.256     ]\n",
      " [ -1.256        0.           0.          -1.256     ]\n",
      " [ -1.256      -12.56         0.          -1.256     ]\n",
      " [ -1.256        0.          -0.7098912   -1.256     ]\n",
      " [ -1.256       -1.33628784 -12.56        -1.723232  ]\n",
      " [-12.56         0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.         -12.56      ]\n",
      " [ -1.256        0.           0.         -12.56      ]\n",
      " [  0.           0.           0.         -12.56      ]\n",
      " [ -1.256        0.           0.         -12.56      ]\n",
      " [ -1.256        0.           0.         -12.56      ]\n",
      " [ -1.256        0.           0.         -12.56      ]\n",
      " [ -1.256        0.           0.         -12.56      ]\n",
      " [ -1.256        0.         -12.56       -12.56      ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 3. Q-learning Algorithm\n",
    "for i in range(epis):\n",
    "    # Reset environment\n",
    "    s = env.reset(seed=5,playerSeed=True)\n",
    "    rAll = 0\n",
    "    d = False\n",
    "    j = 0\n",
    "    tr = False\n",
    "    #The Q-Table learning algorithm\n",
    "    while not d:\n",
    "        #env.render()\n",
    "        j += 1\n",
    "        # Choose action from Q table\n",
    "        a = np.argmax(Q[s, :] + np.random.randn(1, env.action_space.n) * (1. / (i + 1)))\n",
    "        #Get new state & reward from environment\n",
    "        s1, r, d, tr, _ = env.step(a)\n",
    "        #Update Q-Table with new knowledge\n",
    "        Q[s, a] = Q[s, a] + eta * (r + gma * np.max(Q[s1, :]) - Q[s, a])\n",
    "        rAll += r\n",
    "        s = s1\n",
    "        print('\\r'+'interation'+str(j),end='')\n",
    "        #print()\n",
    "        #env.render(i,tr)\n",
    "        #sleep(0.2)\n",
    "    rev_list.append(rAll)\n",
    "    print()\n",
    "    env.render(i,tr)\n",
    "print(\"Reward Sum on all episodes \" + str(sum(rev_list) / epis))\n",
    "print(\"Final Values Q-Table\")\n",
    "print(Q)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Zr772-IGVEz",
    "outputId": "70116d6b-47a9-4dc8-cc1e-97cd5c8f052b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‖==========‖\n",
      "‖█·····██··‖\n",
      "‖····█··█··‖\n",
      "‖·········X‖\n",
      "‖··········‖\n",
      "‖···█······‖\n",
      "‖··········‖\n",
      "‖···█·····█‖\n",
      "‖·······█··‖\n",
      "‖··········‖\n",
      "‖·@········‖\n",
      "‖==========‖\n",
      "Episode:9 Win:False\n"
     ]
    }
   ],
   "source": [
    "env = CustomEnv(10)\n",
    "# Reset environment\n",
    "\n",
    "tr = False\n",
    "ep = 0\n",
    "# The Q-Table learning algorithm\n",
    "for i in range(10):\n",
    "    s = env.reset(seed=5,playerSeed=True)\n",
    "    d = False\n",
    "    while not d:\n",
    "        # Choose action from Q table\n",
    "        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(10+1)))\n",
    "        #Get new state & reward from environment\n",
    "        s1,r,d,tr,_ = env.step(a)\n",
    "        #Update Q-Table with new knowledge\n",
    "        Q[s,a] = Q[s,a] + eta*(r + gma*np.max(Q[s1,:]) - Q[s,a])\n",
    "        s = s1\n",
    "        sleep(0.2)\n",
    "        env.render(ep,tr)\n",
    "    env.render(ep,tr)\n",
    "    sleep(1)\n",
    "    ep = ep+1\n",
    "# Code will stop at d == True, and render one state before it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "towardsdatascience.com/reinforcement-learning-with-openai-d445c2c687d2\n",
    "https://www.mlq.ai/guide-to-deep-reinforcement-learning/\n",
    "https://www.mlq.ai/what-are-convolutional-neural-networks/\n",
    "https://keras.io/guides/writing_a_training_loop_from_scratch/#lowlevel-handling-of-losses-tracked-by-the-model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}