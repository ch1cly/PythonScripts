{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install keyboard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from gym import Env\n",
    "from gym.spaces import Box, Discrete\n",
    "import random\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import keyboard\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://keras.io/guides/writing_a_training_loop_from_scratch/#lowlevel-handling-of-losses-tracked-by-the-model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def actionAsk():\n",
    "    if keyboard.is_pressed('Down'):\n",
    "        return 0\n",
    "    if keyboard.is_pressed('Left'):\n",
    "        return 1\n",
    "    if keyboard.is_pressed('Up'):\n",
    "        return 2\n",
    "    if keyboard.is_pressed('Down'):\n",
    "        return 3\n",
    "    return -1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "class Point2():\n",
    "    def __init__(self, x=0, y=0):\n",
    "        self._info = np.array([x, y], ndmin=1)\n",
    "\n",
    "    @property\n",
    "    def x(self):\n",
    "        return self._info[0]\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._info[1]\n",
    "\n",
    "    @x.setter\n",
    "    def x(self, a):\n",
    "        self._info[0] = a\n",
    "\n",
    "    @y.setter\n",
    "    def y(self, a):\n",
    "        self._info[1] = a\n",
    "\n",
    "    def __add__(self, o):\n",
    "        return Point2(self._info[0] + o._info[0], self._info[1] + o._info[1])\n",
    "\n",
    "    def __sub__(self, o):\n",
    "        return Point2(self._info[0] - o._info[0], self._info[1] - o._info[1])\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if np.all(np.equal(self._info, other._info)):\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "class CustomEnv(Env):\n",
    "    def __init__(self, h=10, w=10):\n",
    "        self.WIDTH = w\n",
    "        self.HEIGHT = h\n",
    "        self.action_space = Discrete(4)\n",
    "        self.observation_space = Box(low=-self.HEIGHT, high=self.HEIGHT, shape=(2, 2), dtype=int)\n",
    "        self.snake = [Point2(0, 0)]\n",
    "        self.food = Point2(0, 0)\n",
    "        self.aim = Point2(0, -1)\n",
    "        self.endGame = False\n",
    "\n",
    "    def inside(self, head):\n",
    "        return -1 < head.x < self.WIDTH and -1 < head.y < self.HEIGHT\n",
    "\n",
    "    def change(self, action):\n",
    "        if action == 0:\n",
    "            self.aim.x = 0\n",
    "            self.aim.y = -1\n",
    "        elif action == 1:\n",
    "            self.aim.x = -1\n",
    "            self.aim.y = 0\n",
    "        elif action == 2:\n",
    "            self.aim.x = 0\n",
    "            self.aim.y = 1\n",
    "        elif action == 3:\n",
    "            self.aim.x = 1\n",
    "            self.aim.y = 0\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def step(self, action):\n",
    "        self.change(action)\n",
    "        head = self.snake[-1] + self.aim\n",
    "        if (not self.inside(head) or head in self.snake) and self.aim != Point2(0, 0):\n",
    "            self.endGame = True\n",
    "            reward = 0.749\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "            self.snake.append(head)\n",
    "\n",
    "            if head == self.food:\n",
    "                while self.food in self.snake:\n",
    "                    self.food = self.rPoint()\n",
    "                reward = 0.000001\n",
    "            else:\n",
    "                prev = np.array([np.abs(self.snake[-2].x - self.food.x), np.abs(self.snake[-2].y - self.food.y)])\n",
    "                cur = np.array([np.abs(self.snake[-1].x - self.food.x), np.abs(self.snake[-1].y - self.food.y)])\n",
    "\n",
    "                if prev[0] < cur[0] or prev[1] < cur[1]:\n",
    "                    reward = 0.25\n",
    "                else:\n",
    "                    reward = 0.09\n",
    "                self.snake.pop(0)\n",
    "\n",
    "        # Setting the placeholder for info\n",
    "        info = len(self.snake)\n",
    "        # Returning the step information\n",
    "        return self.snakePos(), reward, done, info\n",
    "\n",
    "    def render(self, episode, reward):\n",
    "        clear_output(wait=True)\n",
    "        s = ''\n",
    "        for i in range(-1, self.WIDTH + 1):\n",
    "            for j in range(-1, self.HEIGHT + 1):\n",
    "                if Point2(i, j) == self.snake[-1]:\n",
    "                    s = s + '0'\n",
    "                elif Point2(i, j) in self.snake:\n",
    "                    s = s + '█'\n",
    "                elif Point2(i, j) == self.food:\n",
    "                    s = s + 'X'\n",
    "                elif j == -1 or j == self.HEIGHT:\n",
    "                    s = s + '‖'\n",
    "                elif i == -1 or i == self.WIDTH:\n",
    "                    s = s + '='\n",
    "                else:\n",
    "                    s = s + '·'\n",
    "            s = s + '\\n'\n",
    "        s = s + 'Episode:{} Score:{} Snake:{}'.format(episode, reward, len(self.snake))\n",
    "        print(s)\n",
    "\n",
    "    def position(self, pos) -> int:\n",
    "        return pos.x * self.WIDTH + pos.y\n",
    "\n",
    "    def snakePos(self):\n",
    "        obsspc = np.zeros(self.HEIGHT * self.WIDTH, dtype=np.float64)\n",
    "        for i in range(len(self.snake)):\n",
    "            obsspc[self.position(self.snake[i])] = 0.33\n",
    "        obsspc[self.position(self.snake[-1])] = 0.66\n",
    "        obsspc[self.position(self.food)] = 0.99\n",
    "        return obsspc\n",
    "\n",
    "    def rPoint(self) -> Point2:\n",
    "        x = random.randint(0, self.WIDTH - 1)\n",
    "        y = random.randint(0, self.HEIGHT - 1)\n",
    "        return Point2(x, y)\n",
    "\n",
    "    def reset(self, seed=2, playerSeed=False):\n",
    "        if (playerSeed):\n",
    "            random.seed(seed)\n",
    "        else:\n",
    "            t = 1000 * time.time()  # current time in milliseconds\n",
    "            random.seed(int(t) % 2 ** 32)\n",
    "        self.snake = [self.rPoint()]\n",
    "        self.food = self.rPoint()\n",
    "        self.aim = Point2(0, 0)\n",
    "        self.endGame = False\n",
    "        return self.snakePos()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "h = w = 10\n",
    "env = CustomEnv(h, w)\n",
    "#rule\n",
    "#likirelu\n",
    "#sigmoid\n",
    "#th\n",
    "inputs = keras.Input(shape=(h * w,), name=\"digits\")\n",
    "x1 = layers.Dense(256, activation=\"relu\")(inputs)\n",
    "x2 = layers.Dense(256, activation=\"relu\")(x1)\n",
    "x3 = layers.Dense(128, activation=\"relu\")(x2)\n",
    "x4 = layers.Dense(64, activation=\"relu\")(x3)\n",
    "x5 = layers.Dense(32, activation=\"relu\")(x4)\n",
    "outputs = layers.Dense(4, name=\"predictions\")(x5)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# Instantiate an optimizer.\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
    "# Instantiate a loss function.\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epi 134 Training loss (for one batch) at step 74: 12.5800\n",
      "down  is35\n",
      "left  is2\n",
      "up    is37\n",
      "right is0\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "allReward = []\n",
    "allScores = []\n",
    "allSteps = []\n",
    "allDicts = []\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    done = False\n",
    "    reward = 0\n",
    "    agent = env.reset()\n",
    "    score = 0\n",
    "    sumReward = 0\n",
    "    step = 0\n",
    "    info = 1\n",
    "    dict = {1:0,\n",
    "        2:0,\n",
    "        3:0,\n",
    "        0:0}\n",
    "    # Iterate over the batches of the dataset.\n",
    "    #for i in range(100):\n",
    "    while not done and step < 100:\n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables auto-differentiation.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            batch_size = 1\n",
    "\n",
    "            # Prepare the validation dataset.\n",
    "            input = tf.convert_to_tensor(np.array([agent]), dtype=tf.float32)\n",
    "\n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are going to be recorded\n",
    "            # on the GradientTape.\n",
    "            logits = model(input, training=True)  # Logits for this minibatch\n",
    "            agent, reward, done, score = env.step(np.argmax(logits[0]))\n",
    "            sumReward = sumReward + reward\n",
    "            #env.render(epoch,allreward)\n",
    "            step = step + 1\n",
    "            # Compute the loss value for this minibatch.\n",
    "            #loss_value = loss_fn(y_batch_train, logits)\n",
    "            temp = tf.reduce_sum(tf.multiply(logits, tf.convert_to_tensor(0.))),\n",
    "            loss_value = tf.add(temp, tf.convert_to_tensor(121, dtype=tf.float32))\n",
    "\n",
    "        # Use the gradient tape to automatically retrieve\n",
    "        # the gradients of the trainable variables with respect to the loss.\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "        # Run one step of gradient descent by updating\n",
    "        # the value of the variables to minimize the loss.\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        dict[np.argmax(logits[0])] = dict[np.argmax(logits[0])] +1\n",
    "        # Log every 200 batches.\n",
    "        print(\n",
    "            '\\r'+\"Epi %d Training loss (for one batch) at step %d: %.4f\"\n",
    "            % (epoch,step, float(sumReward))\n",
    "\n",
    "        )\n",
    "        print('\\rdown  is'+str(dict[0]))\n",
    "        print('\\rleft  is'+str(dict[1]))\n",
    "        print('\\rup    is'+str(dict[2]))\n",
    "        print('\\rright is'+str(dict[3]))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    allReward.append(sumReward)\n",
    "    allScores.append(len(env.snake))\n",
    "    allSteps.append(step)\n",
    "    allDicts.append(dict)\n",
    "    print('\\r'+\"Seen so far: %s samples\" % epoch)\n",
    "    print('\\r'+\"Score is: %s\" % score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scorestep = []\n",
    "rewardstep = []\n",
    "down = []\n",
    "left = []\n",
    "up =[]\n",
    "right = []\n",
    "for i in range(epochs):\n",
    "    scorestep.append(float(allScores[i])/float(allSteps[i]))\n",
    "    rewardstep.append(float(allReward[i])/float(allSteps[i]))\n",
    "    down.append( allDicts[i][0] / (allDicts[i][0] + allDicts[i][1] + allDicts[i][2] + allDicts[i][3]))\n",
    "    left.append( allDicts[i][1] / (allDicts[i][0] + allDicts[i][1] + allDicts[i][2] + allDicts[i][3]))\n",
    "    up.append(   allDicts[i][2] / (allDicts[i][0] + allDicts[i][1] + allDicts[i][2] + allDicts[i][3]))\n",
    "    right.append(allDicts[i][3] / (allDicts[i][0] + allDicts[i][1] + allDicts[i][2] + allDicts[i][3]))\n",
    "plt.title('score/step')\n",
    "plt.plot(scorestep)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action is3\n",
      "Epi 481 Training loss (for one batch) at step 75: 11.1900\n"
     ]
    }
   ],
   "source": [
    "plt.title('reward/step')\n",
    "plt.plot(rewardstep)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(step,color='red')\n",
    "plt.plot(reward,color='blue')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "downl = plt.plot(down,label = 'down')\n",
    "leftl = plt.plot(left,label ='left')\n",
    "upl = plt.plot(up, label = 'up')\n",
    "rightl = plt.plot(right, right = 'right')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‖==========‖\n",
      "‖··········‖\n",
      "‖··········‖\n",
      "‖··········‖\n",
      "‖··········‖\n",
      "‖··X·······‖\n",
      "‖··········‖\n",
      "‖··········‖\n",
      "‖··········‖\n",
      "‖···0······‖\n",
      "‖··········‖\n",
      "‖==========‖\n",
      "Episode:4 Score:1 Snake:1\n",
      "Epi 4 Training loss (for one batch) at step 1: 0.0100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [55], line 16\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m done \u001B[38;5;129;01mand\u001B[39;00m step \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m100\u001B[39m:\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mconvert_to_tensor(np\u001B[38;5;241m.\u001B[39marray([agent]), dtype\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mfloat32)  \u001B[38;5;66;03m# Logits for this minibatch\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m     action \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m     agent, reward, done, score \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mstep(np\u001B[38;5;241m.\u001B[39margmax(action))\n\u001B[0;32m     18\u001B[0m     env\u001B[38;5;241m.\u001B[39mrender(epi,score)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:2220\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   2211\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[0;32m   2212\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   2213\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2214\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2217\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m   2218\u001B[0m         )\n\u001B[1;32m-> 2220\u001B[0m data_handler \u001B[38;5;241m=\u001B[39m \u001B[43mdata_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data_handler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2223\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2224\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2226\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2227\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2228\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2229\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2230\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_execution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2231\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2233\u001B[0m \u001B[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001B[39;00m\n\u001B[0;32m   2234\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(callbacks, callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1582\u001B[0m, in \u001B[0;36mget_data_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1580\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cluster_coordinator\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1581\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _ClusterCoordinatorDataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1582\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1262\u001B[0m, in \u001B[0;36mDataHandler.__init__\u001B[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001B[0m\n\u001B[0;32m   1259\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution \u001B[38;5;241m=\u001B[39m steps_per_execution\n\u001B[0;32m   1261\u001B[0m adapter_cls \u001B[38;5;241m=\u001B[39m select_data_adapter(x, y)\n\u001B[1;32m-> 1262\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adapter \u001B[38;5;241m=\u001B[39m \u001B[43madapter_cls\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1264\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1266\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1268\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1272\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdistribution_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_strategy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1274\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1277\u001B[0m strategy \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mget_strategy()\n\u001B[0;32m   1279\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:308\u001B[0m, in \u001B[0;36mTensorLikeDataAdapter.__init__\u001B[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001B[0m\n\u001B[0;32m    301\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m indices\n\u001B[0;32m    303\u001B[0m \u001B[38;5;66;03m# We prefetch a single element. Computing large permutations can take\u001B[39;00m\n\u001B[0;32m    304\u001B[0m \u001B[38;5;66;03m# quite a while so we don't want to wait for prefetching over an epoch\u001B[39;00m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;66;03m# boundary to trigger the next permutation. On the other hand, too many\u001B[39;00m\n\u001B[0;32m    306\u001B[0m \u001B[38;5;66;03m# simultaneous shuffles can contend on a hardware level and degrade all\u001B[39;00m\n\u001B[0;32m    307\u001B[0m \u001B[38;5;66;03m# performance.\u001B[39;00m\n\u001B[1;32m--> 308\u001B[0m indices_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mindices_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpermutation\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mprefetch(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    310\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mslice_batch_indices\u001B[39m(indices):\n\u001B[0;32m    311\u001B[0m     \u001B[38;5;124;03m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001B[39;00m\n\u001B[0;32m    312\u001B[0m \n\u001B[0;32m    313\u001B[0m \u001B[38;5;124;03m    This step can be accomplished in several ways. The most natural is\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;124;03m      A Dataset of batched indices.\u001B[39;00m\n\u001B[0;32m    326\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2202\u001B[0m, in \u001B[0;36mDatasetV2.map\u001B[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001B[0m\n\u001B[0;32m   2199\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m deterministic \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m DEBUG_MODE:\n\u001B[0;32m   2200\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `deterministic` argument has no effect unless the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2201\u001B[0m                   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`num_parallel_calls` argument is specified.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 2202\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mMapDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreserve_cardinality\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2203\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2204\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m ParallelMapDataset(\n\u001B[0;32m   2205\u001B[0m       \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   2206\u001B[0m       map_func,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2209\u001B[0m       preserve_cardinality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   2210\u001B[0m       name\u001B[38;5;241m=\u001B[39mname)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5406\u001B[0m, in \u001B[0;36mMapDataset.__init__\u001B[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001B[0m\n\u001B[0;32m   5400\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func \u001B[38;5;241m=\u001B[39m structured_function\u001B[38;5;241m.\u001B[39mStructuredFunctionWrapper(\n\u001B[0;32m   5401\u001B[0m     map_func,\n\u001B[0;32m   5402\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transformation_name(),\n\u001B[0;32m   5403\u001B[0m     dataset\u001B[38;5;241m=\u001B[39minput_dataset,\n\u001B[0;32m   5404\u001B[0m     use_legacy_function\u001B[38;5;241m=\u001B[39muse_legacy_function)\n\u001B[0;32m   5405\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name \u001B[38;5;241m=\u001B[39m name\n\u001B[1;32m-> 5406\u001B[0m variant_tensor \u001B[38;5;241m=\u001B[39m gen_dataset_ops\u001B[38;5;241m.\u001B[39mmap_dataset(\n\u001B[0;32m   5407\u001B[0m     input_dataset\u001B[38;5;241m.\u001B[39m_variant_tensor,  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   5408\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39mfunction\u001B[38;5;241m.\u001B[39mcaptured_inputs,\n\u001B[0;32m   5409\u001B[0m     f\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39mfunction,\n\u001B[0;32m   5410\u001B[0m     use_inter_op_parallelism\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_inter_op_parallelism,\n\u001B[0;32m   5411\u001B[0m     preserve_cardinality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_preserve_cardinality,\n\u001B[0;32m   5412\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_common_args)\n\u001B[0;32m   5413\u001B[0m \u001B[38;5;28msuper\u001B[39m(MapDataset, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(input_dataset, variant_tensor)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3459\u001B[0m, in \u001B[0;36mmap_dataset\u001B[1;34m(input_dataset, other_arguments, f, output_types, output_shapes, use_inter_op_parallelism, preserve_cardinality, metadata, name)\u001B[0m\n\u001B[0;32m   3457\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m   3458\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3459\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3460\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mMapDataset\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother_arguments\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3461\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput_types\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput_shapes\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_shapes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3462\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muse_inter_op_parallelism\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_inter_op_parallelism\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3463\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpreserve_cardinality\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreserve_cardinality\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3464\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   3465\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "episodes = 500\n",
    "rrr = []\n",
    "for epi in range(episodes):\n",
    "    print(\"\\nStart of epoch %d\" % (episodes,))\n",
    "    done = False\n",
    "    reward = 0\n",
    "    agent = env.reset()\n",
    "    score = 0\n",
    "    allreward = 0\n",
    "    step = 0\n",
    "    info = 1\n",
    "    env.render(epi,score)\n",
    "    # Iterate over the batches of the dataset.\n",
    "    while not done and step < 100:\n",
    "        input = tf.convert_to_tensor(np.array([agent]), dtype=tf.float32)  # Logits for this minibatch\n",
    "        action = model.predict(input)\n",
    "        agent, reward, done, score = env.step(np.argmax(action))\n",
    "        env.render(epi,score)\n",
    "        allreward = allreward + reward\n",
    "        step = step + 1\n",
    "        sleep(0.05)\n",
    "        # Log every 200 batches.\n",
    "        print(\n",
    "            '\\r'+\"Epi %d Training loss (for one batch) at step %d: %.4f\"\n",
    "            % (epi,step, float(allreward))\n",
    "        )\n",
    "    rrr.append(allreward)\n",
    "    print(\"Seen so far: %s samples\" % epoch)\n",
    "    print(\"Score is: %s\" % info)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = env.reset()\n",
    "\n",
    "input = tf.convert_to_tensor(np.array([agent]), dtype=tf.float32)  # Logits for this minibatch\n",
    "action = model.predict(input)\n",
    "np.argmax(action)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}